{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9039b7bc",
   "metadata": {},
   "source": [
    "#                 ---Financial Fraud Detection---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02cd843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f50460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "data = pd.read_csv('C:\\\\Users\\\\user\\\\Downloads\\\\Bank_Transaction_Fraud_Detection.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac2ef54",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac322ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0037e794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change data type of date column to datetime\n",
    "data['Transaction_Date'] = pd.to_datetime(data['Transaction_Date'])\n",
    "data['Transaction_Time'] = pd.to_datetime(data['Transaction_Time'], format='%H:%M:%S').dt.time\n",
    "# combine date and time into a single datestamp column\n",
    "data['Transaction_Timestamp'] = pd.to_datetime(\n",
    "    data['Transaction_Date'].astype(str) + ' ' + data['Transaction_Time'].astype(str)\n",
    ")\n",
    "# drop original date and time columns\n",
    "data.drop(columns=['Transaction_Date', 'Transaction_Time'], inplace=True)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04dbbc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check duplicate rows on a specific subset of columns\n",
    "data.duplicated(subset=['Transaction_ID', 'Customer_ID', 'Transaction_Amount', 'Transaction_Timestamp']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658a0b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop unnecessary columns\n",
    "data.drop(columns=['Customer_Email', 'Customer_Contact'], inplace=True)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0551bf7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# covert date and time format to US format\n",
    "data['Transaction_Timestamp'] = data['Transaction_Timestamp'].dt.strftime('%m/%d/%Y %I:%M:%S %p')\n",
    "data['Transaction_Timestamp'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74be7f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns for better readability\n",
    "data.columns = [col.strip().replace(' ', '_').lower() for col in data.columns]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595b2287",
   "metadata": {},
   "source": [
    "## Creating Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2fe829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a SQLite database and storing the cleaned data\n",
    "conn = sqlite3.connect('bank_transactions.db')\n",
    "data.to_sql('transactions', conn, if_exists='replace', index=False)\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43bbeee6",
   "metadata": {},
   "source": [
    "## Load Data from Database "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1074305c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from SQLite database to verify\n",
    "conn = sqlite3.connect('bank_transactions.db')\n",
    "data = pd.read_sql('SELECT * FROM transactions', conn)\n",
    "conn.close()    \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82de2779",
   "metadata": {},
   "source": [
    "## Identify Numeric & Categorical Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6915d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate numerical and categorical columns\n",
    "numerical_cols = data.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_cols = data.select_dtypes(include=['object']).columns.tolist()\n",
    "numerical_cols, categorical_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b13e348",
   "metadata": {},
   "source": [
    "## Encode Categorical and Numeric Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ca57db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding categorical variables\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "label_encoders = {}\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    data[col] = le.fit_transform(data[col])\n",
    "    label_encoders[col] = le\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4812e6",
   "metadata": {},
   "source": [
    "## Split Features and Target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de70556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the dataset into features and target variable\n",
    "X = data.drop(columns=['is_fraud'])\n",
    "y = data['is_fraud']\n",
    "# splitting into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7baa6569",
   "metadata": {},
   "source": [
    "## Scale Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d19c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # scale data\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# scaler = StandardScaler()\n",
    "# X_train = scaler.fit_transform(X_train)\n",
    "# X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a94ce2",
   "metadata": {},
   "source": [
    "## Train Multiple Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f0e103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Multiple Models\n",
    "# import all necessary model libraries\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "# import evaluation metrics\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, precision_score, recall_score, f1_score\n",
    "# initialize models\n",
    "models = {\n",
    "    # 'Logistic Regression': LogisticRegression(max_iter=100)\n",
    "       'Decision Tree': DecisionTreeClassifier()\n",
    "    #  'Random Forest': RandomForestClassifier(),  \n",
    "    #  'Gradient Boosting': GradientBoostingClassifier(),\n",
    "    #  'Support Vector Machine': SVC(probability=True),\n",
    "    #  'XGBoost': XGBClassifier()\n",
    "}\n",
    "# train and evaluate each model\n",
    "results = {}\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_proba = model.predict_proba(X_test)[:, 1]\n",
    "    results[model_name] = {\n",
    "        'Accuracy': accuracy_score(y_test, y_pred),\n",
    "        'Precision': precision_score(y_test, y_pred),\n",
    "        'Recall': recall_score(y_test, y_pred),\n",
    "        'F1 Score': f1_score(y_test, y_pred),   \n",
    "        'Classification Report': classification_report(y_test, y_pred),\n",
    "        'Confusion Matrix': confusion_matrix(y_test, y_pred),   \n",
    "        'ROC AUC': roc_auc_score(y_test, y_proba),\n",
    "       \n",
    "    }\n",
    "    # display results for each model\n",
    "    print(f\"Results for {model_name}:\")\n",
    "    print(f\"Accuracy: {results[model_name]['Accuracy']:.4f}\")\n",
    "    print(f\"Precision: {results[model_name]['Precision']:.4f}\")\n",
    "    print(f\"Recall: {results[model_name]['Recall']:.4f}\")\n",
    "    print(f\"F1 Score: {results[model_name]['F1 Score']:.4f}\")\n",
    "    print(f\"ROC AUC: {results[model_name]['ROC AUC']:.4f}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(results[model_name]['Classification Report'])\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(results[model_name]['Confusion Matrix'])\n",
    "    \n",
    "    # plot confusion matrix for each model\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title(f'Confusion Matrix for {model_name}')\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4332514",
   "metadata": {},
   "source": [
    "## Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71dfde8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "# import joblib\n",
    "import joblib\n",
    "joblib.dump(models['Decision Tree'], 'decision_tree_model.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67e0f06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6fde96fa",
   "metadata": {},
   "source": [
    "## Save label encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd21e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save label encoders\n",
    "joblib.dump(label_encoders, 'label_encoders.pkl')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
